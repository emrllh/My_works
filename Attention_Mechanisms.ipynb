{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgqhS+F9aJ/nTWwL87OgwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrllh/My_works/blob/main/Attention_Mechanisms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "31UtdDGVP91R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Mechanisms\n",
        "\n",
        "The decoder combines the target language input with the context from the encoder to generate its output sequence. The encoder state acts as a guide, providing information about the source language input that helps the decoder make informed predictions about the target language sequence.\n",
        "\n",
        "All the encoder's outputs needs to be fed to the Attention layer, so we must add `return_sequences=True` to the encoder:"
      ],
      "metadata": {
        "id": "wzhmWW6IwEis"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z23Jvl_RRSEK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leKfUIVlPjBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "076be6f1-7dd3-4dd3-db38-c341d29446a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "\u001b[1m2638744/2638744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "path = tf.keras.utils.get_file('spa-eng.zip', origin=url, cache_dir='datasets',\n",
        "                               extract=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-p4UsB7LQTEP"
      },
      "outputs": [],
      "source": [
        "text = (Path(path).with_name('spa-eng')/ 'spa.txt').read_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28noA2UAR87x",
        "outputId": "e7b6c765-055c-432e-8c61-98406976fea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go.\tVe.\n",
            "Go.\tVete.\n",
            "Go.\tVaya.\n",
            "Go.\tVáyase.\n",
            "H.\tHola.\n",
            "Run!\t¡Corre!\n",
            "Run.\tCorred.\n",
            "Who?\tQuén?\n",
            "Fre!\t¡Fuego!\n",
            "F\n"
          ]
        }
      ],
      "source": [
        "\n",
        "text = text.replace('i','').replace('¿','')\n",
        "print(text[:100])\n",
        "pairs = [line.split('\\t') for line in text.splitlines()]\n",
        "#pairs[:10]\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(pairs)\n",
        "sentences_en, sentences_es = zip(*pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INjVbx4PvpFj",
        "outputId": "516ae1ce-43d4-4fed-83a4-1ab9cf8de0e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How borng! => ¡Qué aburrmento!\n",
            "I love sports. => Adoro el deporte.\n",
            "Would you lke to swap jobs? => Te gustaría que ntercambemos los trabajos?\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "  print(sentences_en[i], '=>', sentences_es[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBlpjnBrwPOT"
      },
      "outputs": [],
      "source": [
        "vocab_size = 1000  # most frequent 1000 words will be considered during the text vectorization process.\n",
        "max_length = 50 # max lenght of output sequence\n",
        "text_vec_layer_en = tf.keras.layers.TextVectorization(\n",
        "    vocab_size, output_sequence_length=max_length)\n",
        "text_vec_layer_es = tf.keras.layers.TextVectorization(\n",
        "    vocab_size, output_sequence_length=max_length)\n",
        "text_vec_layer_en.adapt(sentences_en)\n",
        "text_es=text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])\n",
        "#print(list(text_es[:10])) didnt work"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.keras.layers.TextVectorization:` This is a preprocessing layer that converts text into numerical sequences."
      ],
      "metadata": {
        "id": "pkT7XesmCuya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR6rWrNIzXKj",
        "outputId": "2d096602-4961-4138-a09e-f9edd9acfaa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'i', 'to', 'you', 'tom', 'a', 's', 'he']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "text_vec_layer_en.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bthOWVQ2zjeu",
        "outputId": "2f7f2cee-9644-43df-b2b5-182d094eb5fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['', '[UNK]', 'startofseq', 'endofseq', 'de', 'que', 'a', 'no', 'tom', 'la']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_vec_layer_es.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Encoder: Processes the English sentences (X_train, X_valid).\n",
        "- Decoder: Processes the Spanish sentences (X_train_dec, X_valid_dec) and aims to predict the correct translation. The \"startofseq\" token helps the decoder understand the beginning of the target sequence."
      ],
      "metadata": {
        "id": "t1VzJsTDNUjM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSveDmDAzsqM",
        "outputId": "76fbda34-1ee5-43c3-cf95-6c6c3694e10d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'How borng!' b'I love sports.' b'Would you lke to swap jobs?'\n",
            " b'My mother dd nothng but weep.'\n",
            " b'Croata s n the southeastern part of Europe.'], shape=(5,), dtype=string)\n",
            "tf.Tensor(\n",
            "[b'How borng!' b'I love sports.' b'Would you lke to swap jobs?'\n",
            " b'My mother dd nothng but weep.'\n",
            " b'Croata s n the southeastern part of Europe.'], shape=(5,), dtype=string)\n",
            "tf.Tensor(\n",
            "[[437   1   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(1, 50), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[ 14  37   1 141   1   3   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(1, 50), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "X_train = tf.constant(sentences_en[:100_000])\n",
        "print(X_train[:5])\n",
        "X_valid = tf.constant(sentences_en[100_000:])\n",
        "\n",
        "X_train_dec = tf.constant([f'startofseq {s} ' for s in sentences_es[:100_000]])\n",
        "print(X_train[:5])\n",
        "X_valid_dec = tf.constant([f'startofseq {s}' for s in sentences_es[100_000:]])\n",
        "\n",
        "#It iterates through the first 100,000 Spanish sentences (sentences_es)\n",
        "#and adds the suffix \" endofseq\" to each sentence.\n",
        "\n",
        "Y_train = text_vec_layer_es([f'{s} endofseq' for s in sentences_es[:100_000]])\n",
        "print(Y_train[:1])\n",
        "Y_valid = text_vec_layer_es([f'{s} endofseq' for s in sentences_es[100_000:]])\n",
        "print(Y_valid[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmLiGUIL1i40"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
        "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`text_vec_layer_en:` This is an instance of the TextVectorization layer. It's responsible for converting the English text input into numerical IDs\n",
        "\n",
        "`vocab_size`: This argument specifies the size of the vocabulary. It indicates the total number of unique words or tokens that the embedding layer needs to handle.\n",
        "\n",
        "`embed_size`: This argument defines the dimensionality of the word embeddings. It sets the size of the vector that will represent each word. In our case, it's 128, meaning each word will be represented by a 128-dimensional vector.\n",
        "\n",
        "https://colah.github.io/posts/2014-07-NLP-RNNs-Representations/#Word%20Embeddings\n",
        "\n",
        "https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/\n",
        "\n",
        "`mask_zero`=True: This argument is optional but important for handling padding in sequences. When set to True, it tells the embedding layer to ignore any input values of 0. This is useful when you have variable-length sequences and need to pad them with 0s to make them the same length. By masking these padding values, you prevent them from influencing the model's learning"
      ],
      "metadata": {
        "id": "zlK8WnkzPqay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "embed_size = 128\n",
        "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
        "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
        "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
        "                                                    mask_zero=False)\n",
        "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
        "                                                    mask_zero=False)\n",
        "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
      ],
      "metadata": {
        "id": "0JpEwuKDOztb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "tf.random.set_seed(42)\n",
        "encoder = tf.keras.layers.Bidirectional(\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True, return_state=True)\n",
        ")"
      ],
      "metadata": {
        "id": "vUmYrvfqwGBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#ensures that the decoder outputs a sequence of hidden states,\n",
        "#one for each input timestep.\n",
        "\n",
        "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
        "\n",
        "encoder_state = [tf.concat(encoder_state[::2], axis=-1),  # short-term (0 & 2)\n",
        "                 tf.concat(encoder_state[1::2], axis=-1)] # long-term (1 & 3)\n",
        "\n"
      ],
      "metadata": {
        "id": "-q9DJZeWwhup",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "collapsed": true,
        "outputId": "5899a985-11f9-4eb5-d21a-b7d59e0bc43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "TypeError: object of type 'KerasTensor' has no len()\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-5c0766788a9e>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mencoder_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m encoder_state = [tf.concat(encoder_state[::2], axis=-1),  # short-term (0 & 2)\n\u001b[0m\u001b[1;32m      7\u001b[0m                  tf.concat(encoder_state[1::2], axis=-1)] # long-term (1 & 3)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: TypeError: object of type 'KerasTensor' has no len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#After The error with @ NotImplementedError: Iterating over a symbolic KerasTensor is not supported.\n",
        "#the below code worked fine\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self,units, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.units = units\n",
        "    self.bidirectional = tf.keras.layers.Bidirectional(\n",
        "        tf.keras.layers.LSTM(units, return_sequences=True, return_state=True)\n",
        "    )\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    encoder_outputs, *encoder_state = self.bidirectional(inputs)\n",
        "\n",
        "    encoder_state = [\n",
        "        tf.concat(encoder_state[::2], axis=-1), #short_term (0 & 2)\n",
        "        tf.concat(encoder_state[1::2], axis=-1) #long_term (1 $ 3)\n",
        "    ]\n",
        "    return encoder_outputs, encoder_state\n"
      ],
      "metadata": {
        "id": "FxTGMaP24Y1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder =EncoderLayer(256)\n",
        "encoder_outputs, encoder_state = encoder(encoder_embeddings)"
      ],
      "metadata": {
        "id": "FOzk8BaPBM2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
        "\n",
        "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)\n"
      ],
      "metadata": {
        "id": "T28qFGH7CZmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Now let's add the Attention layer and the output layer:\n",
        "attention_layer = tf.keras.layers.Attention()\n",
        "\n",
        "attention_outputs = attention_layer([decoder_outputs, encoder_outputs])\n",
        "\n",
        "output_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
        "\n",
        "Y_proba = output_layer(attention_outputs)\n"
      ],
      "metadata": {
        "id": "tHb9bFKSxIoU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "collapsed": true,
        "outputId": "6f1852f8-2e9c-4c80-8212-a5d6ec6cbc9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-e68490ff79ff>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mattention_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moutput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py\u001b[0m in \u001b[0;36m__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__tf_tensor__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;34m\"A KerasTensor cannot be used as input to a TensorFlow function. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;34m\"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 128\n",
        "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
        "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
        "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
        "                                                    mask_zero=False)\n",
        "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
        "                                                    mask_zero=False)\n",
        "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
      ],
      "metadata": {
        "id": "C3mwc05IU_QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.keras.Model` is a subclass of `tf.keras.layers.Layer` that represents a complete model. It groups layers together and provides methods for training, evaluation, and prediction.\n",
        "\n",
        "The main difference between the two is that a Layer is a single unit of computation, while a Model is a collection of layers that work together to perform a specific task."
      ],
      "metadata": {
        "id": "PsqcXObRLgJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the encoder, decoder, and attention layer within a Keras Model\n",
        "# This ensures that all operations are treated symbolically\n",
        "\n",
        "class AttentionLayer(tf.keras.Model):\n",
        "\n",
        "  def __init__(self,units, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.encoder= EncoderLayer(units)\n",
        "    self.decoder = tf.keras.layers.LSTM(units * 2, return_sequences=True)\n",
        "    self.attention_layer = tf.keras.layers.Attention()\n",
        "    self.output_layer = tf.keras.layers.Dense(vocab_size, activation= 'softmax')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    encoder_embeddings, decoder_embeddings = inputs\n",
        "    encoder_outputs, encoder_state = self.encoder(encoder_embeddings)\n",
        "    decoder_outputs = self.decoder(decoder_embeddings, initial_state=encoder_state)\n",
        "    attention_outputs = self.attention_layer([decoder_outputs, encoder_outputs])\n",
        "    Y_proba = self.output_layer(attention_outputs)\n",
        "    return Y_proba"
      ],
      "metadata": {
        "id": "-Ns195F2KlCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= AttentionLayer(256)\n",
        "Y_proba = model([encoder_embeddings, decoder_embeddings])"
      ],
      "metadata": {
        "id": "Wr2qrq0MUFoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combining both class functions\n",
        "class Layers(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "    self.encoder = tf.keras.layers.Bidirectional(\n",
        "        tf.keras.layers.LSTM(256, return_sequences=True, return_state=True))\n",
        "    self.decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
        "    self.attention_layer = tf.keras.layers.Attention()\n",
        "    self.output_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    encoder_outputs, *encoder_state = self.encoder(inputs) # the data you fed into the model for processing.\n",
        "    encoder_state = [\n",
        "        tf.concat(encoder_state[::2], axis=-1),\n",
        "        tf.concat(encoder_state[1::2], axis=-1)\n",
        "    ]\n",
        "    decoder_outputs = self.decoder(decoder_embeddings, initial_state= encoder_state)\n",
        "    attention_outputs = self.attention_layer([decoder_outputs, encoder_outputs])\n",
        "    Y_proba = self.output_layer(attention_outputs)\n",
        "\n",
        "    return output_layer"
      ],
      "metadata": {
        "id": "ezuwEwlgMqu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_comb = tf.keras.Model(inputs= [encoder_inputs, decoder_inputs],\n",
        "                       outputs = [Y_proba])\n",
        "\n",
        "model_comb.compile(loss='sparse_categorical_crossentropy', optimizer='nadam',\n",
        "                                  metrics=['accuracy'])\n",
        "\n",
        "model_comb.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
        "                    validation_data=((X_valid, X_valid_dec), Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbC5coovWzO1",
        "outputId": "81411b0a-db75-4f6c-b489-b814c70bfa5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 28ms/step - accuracy: 0.9744 - loss: 0.0936 - val_accuracy: 0.9586 - val_loss: 0.1914\n",
            "Epoch 2/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 28ms/step - accuracy: 0.9759 - loss: 0.0876 - val_accuracy: 0.9585 - val_loss: 0.1965\n",
            "Epoch 3/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.9770 - loss: 0.0826 - val_accuracy: 0.9584 - val_loss: 0.1997\n",
            "Epoch 4/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 28ms/step - accuracy: 0.9779 - loss: 0.0782 - val_accuracy: 0.9582 - val_loss: 0.2047\n",
            "Epoch 5/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 27ms/step - accuracy: 0.9789 - loss: 0.0743 - val_accuracy: 0.9580 - val_loss: 0.2093\n",
            "Epoch 6/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 27ms/step - accuracy: 0.9797 - loss: 0.0708 - val_accuracy: 0.9578 - val_loss: 0.2138\n",
            "Epoch 7/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.9802 - loss: 0.0682 - val_accuracy: 0.9576 - val_loss: 0.2177\n",
            "Epoch 8/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 28ms/step - accuracy: 0.9810 - loss: 0.0651 - val_accuracy: 0.9578 - val_loss: 0.2207\n",
            "Epoch 9/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 27ms/step - accuracy: 0.9817 - loss: 0.0624 - val_accuracy: 0.9575 - val_loss: 0.2255\n",
            "Epoch 10/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 27ms/step - accuracy: 0.9822 - loss: 0.0598 - val_accuracy: 0.9573 - val_loss: 0.2298\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79b16459f5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_attention = tf.keras.Model(inputs= [encoder_inputs, decoder_inputs],\n",
        "                       outputs = [Y_proba])\n",
        "\n",
        "model_attention.compile(loss='sparse_categorical_crossentropy', optimizer='nadam',\n",
        "                                  metrics=['accuracy'])\n",
        "\n",
        "model_attention.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
        "                    validation_data=((X_valid, X_valid_dec), Y_valid))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tHMAx6l91QlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e06adf6-d6f7-4ec3-9506-ef536f7a2c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 27ms/step - accuracy: 0.9004 - loss: 0.6324 - val_accuracy: 0.9415 - val_loss: 0.2718\n",
            "Epoch 2/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 27ms/step - accuracy: 0.9458 - loss: 0.2454 - val_accuracy: 0.9534 - val_loss: 0.2016\n",
            "Epoch 3/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 29ms/step - accuracy: 0.9552 - loss: 0.1904 - val_accuracy: 0.9567 - val_loss: 0.1835\n",
            "Epoch 4/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 28ms/step - accuracy: 0.9597 - loss: 0.1665 - val_accuracy: 0.9583 - val_loss: 0.1761\n",
            "Epoch 5/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 33ms/step - accuracy: 0.9630 - loss: 0.1496 - val_accuracy: 0.9588 - val_loss: 0.1745\n",
            "Epoch 6/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 30ms/step - accuracy: 0.9658 - loss: 0.1359 - val_accuracy: 0.9586 - val_loss: 0.1769\n",
            "Epoch 7/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 31ms/step - accuracy: 0.9677 - loss: 0.1259 - val_accuracy: 0.9592 - val_loss: 0.1774\n",
            "Epoch 8/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 32ms/step - accuracy: 0.9697 - loss: 0.1155 - val_accuracy: 0.9590 - val_loss: 0.1808\n",
            "Epoch 9/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 31ms/step - accuracy: 0.9715 - loss: 0.1072 - val_accuracy: 0.9588 - val_loss: 0.1850\n",
            "Epoch 10/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 30ms/step - accuracy: 0.9731 - loss: 0.1000 - val_accuracy: 0.9587 - val_loss: 0.1875\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79b1dc66e7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_attention.history.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PKUZa3oQabz",
        "outputId": "f4597164-6a63-4b80-c6bc-40e0cda7540e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.91878741979599,\n",
              "  0.9491721987724304,\n",
              "  0.9564043879508972,\n",
              "  0.9605749845504761,\n",
              "  0.9636824131011963,\n",
              "  0.966299295425415,\n",
              "  0.9684415459632874,\n",
              "  0.970363974571228,\n",
              "  0.972104549407959,\n",
              "  0.9735676646232605],\n",
              " 'loss': [0.4432101845741272,\n",
              "  0.22556480765342712,\n",
              "  0.18337608873844147,\n",
              "  0.16158923506736755,\n",
              "  0.14565828442573547,\n",
              "  0.13279157876968384,\n",
              "  0.12202385812997818,\n",
              "  0.11265404522418976,\n",
              "  0.10467331111431122,\n",
              "  0.0978928804397583],\n",
              " 'val_accuracy': [0.9414669275283813,\n",
              "  0.9534192681312561,\n",
              "  0.95668625831604,\n",
              "  0.9582793116569519,\n",
              "  0.9588291645050049,\n",
              "  0.9586192965507507,\n",
              "  0.9591705799102783,\n",
              "  0.9589720368385315,\n",
              "  0.9587769508361816,\n",
              "  0.9587332606315613],\n",
              " 'val_loss': [0.2718157470226288,\n",
              "  0.201589435338974,\n",
              "  0.1834685206413269,\n",
              "  0.1761321723461151,\n",
              "  0.1744513213634491,\n",
              "  0.17688174545764923,\n",
              "  0.1773817241191864,\n",
              "  0.18084217607975006,\n",
              "  0.18504217267036438,\n",
              "  0.1875397115945816]}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_attention.save('/content/drive/MyDrive/my_model.keras')"
      ],
      "metadata": {
        "id": "bHPUzJZnP5Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence_en):\n",
        "    # Convert the input sentence to numerical representation\n",
        "    sentence_en_vec = text_vec_layer_en(sentence_en).numpy()\n",
        "\n",
        "    translation = \"\"\n",
        "    for word_idx in range(max_length):\n",
        "        X = np.array([sentence_en_vec])  # encoder input\n",
        "        X_dec = text_vec_layer_es([\"startofseq \" + translation]).numpy() # decoder input\n",
        "        # Reshape X_dec to match expected input shape\n",
        "        X_dec = X_dec.reshape(1, -1)\n",
        "        y_proba = model.predict((X, X_dec))[0, word_idx]  # last token's probas\n",
        "        predicted_word_id = np.argmax(y_proba)\n",
        "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
        "        if predicted_word == \"endofseq\":\n",
        "            break\n",
        "        translation += \" \" + predicted_word\n",
        "    return translation.strip()"
      ],
      "metadata": {
        "id": "_Y96Ku3WQKC6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}